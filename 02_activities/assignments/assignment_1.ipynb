{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8ab56f",
   "metadata": {},
   "source": [
    "# Advanced Image Classification with ImageNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c630244b8fe2847",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this assignment, you will be asked to develop a convolutional neural network (CNN) to classify images from the CIFAR-100 dataset. At each step, you'll be guided through the process of developing a model architecture to solve a problem. Your goal is to create a CNN that attains at least 55% accuracy on the validation set.\n",
    "\n",
    "### The CIFAR-100 Dataset\n",
    "\n",
    "The [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60000 32x32 colour images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 500 images from each class.\n",
    "\n",
    "### Tools\n",
    "\n",
    "You will use Keras with TensorFlow to develop your CNN. For this assignment, it's strongly recommended that you use a GPU to accelerate your training, or else you might find it difficult to train your network in a reasonable amount of time. If you have a computer with a GPU that you wish to use, you can follow the [TensorFlow instructions](https://www.tensorflow.org/install/) for installing TensorFlow with GPU support. Otherwise, you can use [Google Colab](https://colab.research.google.com/) to complete this assignment. Colab provides free access to GPU-enabled machines. If you run into any issues, please contact us as soon as possible so that we can help you resolve them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab62988ece1528d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1: Data Exploration and Preprocessing (Complete or Incomplete)\n",
    "\n",
    "### 1a: Load and Explore the Dataset\n",
    "\n",
    "- Use the code below to download the dataset.\n",
    "- Explore the dataset: examine the shape of the training and test sets, the dimensions of the images, and the number of classes. Show a few examples from the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820fcdc5ae52ae2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:04:08.432758Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386b4072078138f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the shape of the training and test sets\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Dimensions of the images\n",
    "image_shape = x_train.shape[1:]\n",
    "print(f\"Image dimensions: {image_shape}\")\n",
    "\n",
    "# Display a few examples from the training set\n",
    "def plot_examples(x, y, classes, num_examples=10):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.title(f\"Class: {y[i][0]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot 10 examples from the training set\n",
    "plot_examples(x_train, y_train, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49291da3a819ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1b: Data Preprocessing (4 Marks)\n",
    "\n",
    "- With the data downloaded, it's time to preprocess it. Start by normalizing the images so that they all have pixel values in the range [0, 1].\n",
    "- Next, convert the labels to one-hot encoded vectors.\n",
    "- Finally, split the training set into training and validation sets. Use 80% of the training set for training and the remaining 20% for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c10172fa72d0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the images to have pixel values [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Split the training set into training and validation sets (80% training, 20% validation)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shapes of the new training and validation sets\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {x_val.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")\n",
    "\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993757f08c89db7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 2: Model Development (Complete or Incomplete)\n",
    "\n",
    "### Task 2a: Create a Baseline CNN Model\n",
    "\n",
    "- Design a CNN architecture. Your architecture should use convolutional layers, max pooling layers, and dense layers. You can use any number of layers, and you can experiment with different numbers of filters, filter sizes, strides, padding, etc. The design doesn't need to be perfect, but it should be unique to you.\n",
    "- Print out the model summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edafdaf887b8d5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create a baseline CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third convolutional block\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))  # Add dropout for regularization\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))  # Add dropout for regularization\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print out the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546324c007c73db5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 2b: Compile the model\n",
    "\n",
    "- Select an appropriate loss function and optimizer for your model. These can be ones we have looked at already, or they can be different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39f4ba69d684e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfe0ef",
   "metadata": {},
   "source": [
    "- Briefly explain your choices (one or two sentences each).\n",
    "- <b>Loss function:</b> I use categorical cross-entropy as our loss function because it works well for classifying images into 100 categories.\n",
    "- <b>Optimizer:</b> I chose the Adam optimizer because it adjusts the learning rate to help the model converge faster and perform well for image classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653fba928413b9f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 3: Model Training and Evaluation (Complete or Incomplete)\n",
    "\n",
    "### Task 3a: Train the Model\n",
    "\n",
    "- Train your model for an appropriate number of epochs. Explain your choice of the number of epochs used - you can change this number before submitting your assignment.\n",
    "\n",
    "- I started with 20 epochs, a reasonable number to see if the model starts to overfit or if the validation accuracy continues to improve. We can adjust this number based on the model's performance.\n",
    "\n",
    "- Use a batch size of 32.\n",
    "\n",
    "- Is a common choice that balances memory usage and convergence speed.\n",
    "\n",
    "- Use the validation set for validation.\n",
    "\n",
    "- I used the validation set to monitor the model's performance and adjust hyperparameters as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de74f274ad08546",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48615c26b99d2e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 3b: Accuracy and other relevant metrics on the test set\n",
    "\n",
    "- Report the accuracy of your model on the test set.\n",
    "- While accuracy is a good metric, there are many other ways to numerically evaluate a model. Report at least one other metric, and explain what it measures and how it is calculated.\n",
    "\n",
    "- <b>Accuracy:</b> 0.36640000343322754\n",
    "\n",
    "- <b>Other metrics:</b> precision, recall and F1-score.\n",
    "\n",
    "- <b>Reason for selection:</b> The F1-score is selected because it provides a balance between precision and recall, especially useful when dealing with imbalanced datasets. It is the harmonic mean of precision and recall, giving a single metric that considers both false positives and false negatives.\n",
    "\n",
    "- <b>Value of metric:</b> Precision: 0.3734036699660381, Recall: 0.3664 and \n",
    "F1-score: 0.3595827482163865\n",
    "\n",
    "- <b>Interpretation of metric value:</b> A higher F1-score indicates better balance between precision and recall, meaning the model performs well in identifying positive instances without too many false positives or false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670665fda92fb0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T17:49:39.016880Z",
     "start_time": "2024-01-26T17:49:39.012100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "\n",
    "# Extract the precision, recall, and F1-score for the overall performance\n",
    "precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall']\n",
    "f1_score = report['weighted avg']['f1-score']\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2d836d4e8ce99",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 3c: Visualize the model's learning\n",
    "\n",
    "- Plot the training accuracy and validation accuracy with respect to epochs.\n",
    "\n",
    "- Select an image that the model correctly classified in the test set, and an image that the model incorrectly classified in the test set. Plot the images and report the model's classification probabilities for each.\n",
    "\n",
    "- Briefly discuss the results. What do the plots show? \n",
    "- The plots show the accuracy of the model on the training and validation sets over the epochs. If the validation accuracy is significantly lower than the training accuracy, it might indicate overfitting. If both accuracies improve and converge, it suggests good generalization.\n",
    "\n",
    "Do the results make sense?\n",
    "- For the Correctly Classified Image, the image is correctly classified by the model. The predicted probabilities should show a high value for the correct class, indicating the model's confidence.\n",
    "- For the Incorrectly Classified Image, the image is incorrectly classified by the model. The predicted probabilities might be spread across different classes, indicating uncertainty, or show high confidence in an incorrect class, suggesting a model mistake.\n",
    "\n",
    "- What do the classification probabilities indicate?\n",
    "- The classification probabilities indicate the model's confidence in its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b214475a496ca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T17:50:59.733968Z",
     "start_time": "2024-01-26T17:50:59.730635Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the training history\n",
    "plot_training_history(history)\n",
    "\n",
    "# Select an image correctly classified by the model\n",
    "correct_indices = np.where(y_pred_classes == y_true)[0]\n",
    "incorrect_indices = np.where(y_pred_classes != y_true)[0]\n",
    "\n",
    "def plot_image_with_probabilities(image, true_label, predicted_probs, classes):\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True label: {true_label}\\nPredicted probabilities:\\n{predicted_probs}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot a correctly classified image\n",
    "correct_index = correct_indices[0]\n",
    "correct_image = x_test[correct_index]\n",
    "correct_true_label = y_true[correct_index]\n",
    "correct_predicted_probs = y_pred[correct_index]\n",
    "\n",
    "plot_image_with_probabilities(correct_image, correct_true_label, correct_predicted_probs, num_classes)\n",
    "\n",
    "# Plot an incorrectly classified image\n",
    "incorrect_index = incorrect_indices[0]\n",
    "incorrect_image = x_test[incorrect_index]\n",
    "incorrect_true_label = y_true[incorrect_index]\n",
    "incorrect_predicted_probs = y_pred[incorrect_index]\n",
    "\n",
    "plot_image_with_probabilities(incorrect_image, incorrect_true_label, incorrect_predicted_probs, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648758ebea0561d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 4: Model Enhancement (Complete or Incomplete)\n",
    "\n",
    "### Task 4a: Implementation of at least one advanced technique\n",
    "\n",
    "- Now it's time to improve your model. Implement at least one technique to improve your model's performance. You can use any of the techniques we have covered in class, or you can use a technique that we haven't covered. If you need inspiration, you can refer to the [Keras documentation](https://keras.io/).\n",
    "\n",
    "**KERAS TECHNIQUE**: Data Augmentation\n",
    "\n",
    "- Explain the technique you used and why you chose it.\n",
    "Data augmentation increases the variability of the training dataset, making the model more robust and less likely to overfit. This can lead to improved performance on the validation and test sets.\n",
    "\n",
    "- If you used a technique that requires tuning, explain how you selected the values for the hyperparameters.\n",
    "I used a standard set of image adjustments without extensive fine-tuning. These adjustments typically work well for image classification tasks. However, I fine-tuned the choice of adjustments and their ranges based on experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3659ac83122567f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Fit the generator to the training data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Retrain the model using data augmentation\n",
    "history_augmented = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    steps_per_epoch=len(x_train) // batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_augmented, test_accuracy_augmented = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss after augmentation: {test_loss_augmented}\")\n",
    "print(f\"Test accuracy after augmentation: {test_accuracy_augmented}\")\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_augmented = model.predict(x_test)\n",
    "y_pred_classes_augmented = np.argmax(y_pred_augmented, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate a classification report\n",
    "report_augmented = classification_report(y_true, y_pred_classes_augmented, output_dict=True)\n",
    "print(classification_report(y_true, y_pred_classes_augmented))\n",
    "\n",
    "# Extract the precision, recall, and F1-score for the overall performance\n",
    "precision_augmented = report_augmented['weighted avg']['precision']\n",
    "recall_augmented = report_augmented['weighted avg']['recall']\n",
    "f1_score_augmented = report_augmented['weighted avg']['f1-score']\n",
    "\n",
    "print(f\"Precision after augmentation: {precision_augmented}\")\n",
    "print(f\"Recall after augmentation: {recall_augmented}\")\n",
    "print(f\"F1-score after augmentation: {f1_score_augmented}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9467a483a1dd5d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 4b: Evaluation of the enhanced model\n",
    "\n",
    "- Re-train your model using the same number of epochs as before.\n",
    "- Compare the accuracy and other selected metric on the test set to the results you obtained before.\n",
    "- As before, plot the training accuracy and validation accuracy with respect to epochs, and select an image that the model correctly classified in the test set, and an image that the model incorrectly classified in the test set. Plot the images and report the model's classification probabilities for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4701b36dc8fc55",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=None):\n",
    "    # Your code here\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    # More of your code here\n",
    "\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plot_training_history(history_augmented, title='Training and Validation Accuracy with Data Augmentation')\n",
    "\n",
    "# Select an image correctly classified by the model\n",
    "correct_indices_augmented = np.where(y_pred_classes_augmented == y_true)[0]\n",
    "incorrect_indices_augmented = np.where(y_pred_classes_augmented != y_true)[0]\n",
    "\n",
    "# Plot a correctly classified image\n",
    "correct_index_augmented = correct_indices_augmented[0]\n",
    "correct_image_augmented = x_test[correct_index_augmented]\n",
    "correct_true_label_augmented = y_true[correct_index_augmented]\n",
    "correct_predicted_probs_augmented = y_pred_augmented[correct_index_augmented]\n",
    "\n",
    "plot_image_with_probabilities(correct_image_augmented, correct_true_label_augmented, correct_predicted_probs_augmented, num_classes)\n",
    "\n",
    "# Plot an incorrectly classified image\n",
    "incorrect_index_augmented = incorrect_indices_augmented[0]\n",
    "incorrect_image_augmented = x_test[incorrect_index_augmented]\n",
    "incorrect_true_label_augmented = y_true[incorrect_index_augmented]\n",
    "incorrect_predicted_probs_augmented = y_pred_augmented[incorrect_index_augmented]\n",
    "\n",
    "plot_image_with_probabilities(incorrect_image_augmented, incorrect_true_label_augmented, incorrect_predicted_probs_augmented, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadfc848700215e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Task 4c: Discussion of the results\n",
    "\n",
    "- Briefly discuss the results.\n",
    "- Did the model's performance improve?\n",
    "- Yes, the model's performance improved. The test accuracy increased from 36.64% to 40.77%, and there were improvements in precision, recall, and F1-score as well.\n",
    "\n",
    "- Why do you think this is?\n",
    "- The improvement is likely due to data augmentation. By artificially increasing the diversity of the training data through transformations like rotations, shifts, flips, and zooms, the model learned to generalize better and became more robust to variations in the images, reducing overfitting.\n",
    "\n",
    "- Do you think there is room for further improvement? Why or why not?\n",
    "- there is room for further improvement. The current performance indicates that the model can still be enhanced. Techniques such as more sophisticated data augmentation, regularization methods like dropout and batch normalization, and fine-tuning the model architecture and hyperparameters could further boost performance.\n",
    "\n",
    "- What other techniques might you try in the future?\n",
    "- Dropout: To prevent overfitting by randomly dropping units during training.\n",
    "- Learning Rate Schedulers: To adjust the learning rate dynamically.\n",
    "- Transfer Learning: Using pre-trained models and fine-tuning them on CIFAR-100.\n",
    "\n",
    "- Your answer should be no more than 200 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415f68f",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "| Criteria | Complete                                                          | Incomplete                                                    |\n",
    "| -------- | ----------------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| Task 1   | The task has been completed successfully and there are no errors. | The task is still incomplete and there is at least one error. |\n",
    "| Task 2   | The task has been completed successfully and there are no errors. | The task is still incomplete and there is at least one error. |\n",
    "| Task 3   | The task has been completed successfully and there are no errors. | The task is still incomplete and there is at least one error. |\n",
    "| Task 4   | The task has been completed successfully and there are no errors. | The task is still incomplete and there is at least one error. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c10bc",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "\n",
    "- Submission Due Date: `11:59 PM - 28/07/2024`\n",
    "- The branch name for your repo should be: `assignment-1`\n",
    "- What to submit for this assignment:\n",
    "  - This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/fredylrincon/deep_learning/pull/<pr_id>`\n",
    "  - Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "\n",
    "- [X] Created a branch with the correct naming convention.\n",
    "- [X] Ensured that the repository is public.\n",
    "- [X] Reviewed the PR description guidelines and adhered to them.\n",
    "- [X] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
